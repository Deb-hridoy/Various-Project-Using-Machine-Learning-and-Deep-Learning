# -*- coding: utf-8 -*-
"""Cat or Dogs image Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/152pEw8JR7c3MRE750qR1lu-KgFzKrm2f
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
from torch import nn
from torchvision import transforms
from torchvision.transforms import ToTensor
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import os

device = "cuda" if torch.cuda.is_available() else "cpu"
device

# Change this to the path where your dataset is stored in Google Drive
train_dataset_path = '/content/drive/MyDrive/Data cat and dog/training set'
test_dataset_path = '/content/drive/MyDrive/Data cat and dog/test set'

def walk_through_directory(directory_path):
  for dirpath, dirnames, filenames in os.walk(directory_path):
    print(f"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}.")

walk_through_directory(train_dataset_path)

walk_through_directory(test_dataset_path)

import random
from PIL import Image
import pathlib

train_data_path = '/content/drive/MyDrive/Data cat and dog/training set/Dogs'
test_data_path = '/content/drive/MyDrive/Data cat and dog/test set/cats'

train_data_path = pathlib.Path(train_data_path)
test_data_path = pathlib.Path(test_data_path)

train_image_path_list = list(train_data_path.glob("*.jpg"))
test_image_path_list = list(test_data_path.glob("*.jpg"))

print(f"Total train dog image: {len(train_image_path_list)}")
print(f"Total train dog image list: {train_image_path_list}")

print(f"Total test cat image: {len(test_image_path_list)}")
print(f"Total test cat image list: {test_image_path_list}")

random_train_image_path = random.choice(train_image_path_list)
random_test_image_path = random.choice(test_image_path_list)

image_class = random_train_image_path.parent.stem

image_open_train = Image.open(random_train_image_path)
image_open_test = Image.open(random_test_image_path)

print(f"Image class: {image_class}")
print(f"Image height: {image_open_train.height}")
print(f"Image width:{image_open_train.width}")

#image_open_test
image_open_test

# plot the above image as array
image_as_array = np.asarray(image_open_train)
print(f"Image dtype: {image_as_array.dtype}")
print(f"Image as array: {image_as_array}")

plt.figure(figsize=(10, 7))
plt.imshow(image_as_array)
plt.title(f"Image class: {image_class} , Image shape: {image_as_array.shape}")
plt.axis(False)

from torch.utils.data  import dataloader
from torchvision import datasets, transforms

data_transforms = transforms.Compose([transforms.Resize(size=(64, 64)),
                                    transforms.RandomHorizontalFlip(p=0.5),
                                    transforms.ToTensor()
                                    ])

# test one image
transforms = data_transforms(image_open_train)
print(f"Transformed image dtype: {transforms.dtype}")
print(transforms)

# Transform the all image in train and test
train_data = datasets.ImageFolder(root=train_dataset_path,
                                  transform=data_transforms,
                                  target_transform=None)
test_data = datasets.ImageFolder(root=test_dataset_path,
                                 transform=data_transforms,
                                 target_transform=None)

train_data, test_data

len(train_data), len(test_data)

class_names = train_data.classes
class_names

class_to_index = train_data.class_to_idx
class_to_index

img , label = train_data[1][0], train_data[1][1]   # First item in the train dataset
image_permute = img.permute(1,2,0)
print(f"Original Image shape: {img.shape}")
print(f"Permuted Image shape: {image_permute.shape}")

plt.figure(figsize=(10, 7))
plt.imshow(image_permute)
plt.title(class_names[label], fontsize=14)
plt.axis(False)
#plt.show()

from torch.utils.data import DataLoader
Num_Workers = os.cpu_count()
Batch_Size = 32

train_dataloader = DataLoader(dataset=train_data,
                              batch_size=Batch_Size,
                              num_workers=Num_Workers,
                              shuffle=True)

test_dataloader = DataLoader(dataset=test_data,
                             batch_size=Batch_Size,
                             num_workers=Num_Workers,
                             shuffle=False)

train_features_batch, train_labels_batch = next(iter(train_dataloader))
train_features_batch.shape, train_labels_batch.shape

class TinyVGG(nn.Module):
  def __init__(self, input_shape:int,
               hidden_units:int,
               output_shape:int):
    super().__init__()
    self.Conv_block_1 = nn.Sequential(
        nn.Conv2d(
            in_channels=input_shape,
            out_channels=hidden_units,
            kernel_size=3,
            stride=1,
            padding=0
        ),
        nn.ReLU(),
        nn.Conv2d(
            in_channels=hidden_units,
            out_channels=hidden_units,
            kernel_size=3,
            stride=1,
            padding=0
        ),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
    )
    self.Conv_block_2 = nn.Sequential(
        nn.Conv2d(
            in_channels=hidden_units,
            out_channels=hidden_units,
            kernel_size=3,
            stride=1,
            padding=0
        ),
        nn.ReLU(),
        nn.Conv2d(
            in_channels=hidden_units,
            out_channels=hidden_units,
            kernel_size=3,
            stride=1,
            padding=0
        ),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2,
                     stride=2),
    )
    self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(
            in_features = hidden_units*13*13,
            out_features=output_shape
        )
    )
  def forward(self, x):
    x = self.Conv_block_1(x)
    x = self.Conv_block_2(x)
    x = self.classifier(x)
    return x

model_0 = TinyVGG(input_shape=3,
                  hidden_units=10,
                  output_shape=len(class_names)).to(device)

model_0

loss_function = nn.CrossEntropyLoss()
optimize_the_function = torch.optim.Adam(params=model_0.parameters(), lr=0.001)

import requests
from pathlib import Path

if Path("helper_functions.py").is_file():
  print(f"helper_functions.py already exists")
else:
  request = requests.get("https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py")
  with open("helper_functions.py" , "wb") as file:
    file.write(request.content)

torch.manual_seed(42)
#torch.cuda.manual_seed(42)

#from helper_functions import accuracy_fn
from timeit import default_timer as timer
from tqdm.auto import tqdm

epochs = 100

train_time_start = timer()

results = {"train_loss": [],
           "train_accuracy": [],
           "test_loss": [],
           "test_accuracy": []}

for epoch in tqdm(range(epochs)):

  train_loss, train_accuracy = 0, 0

  for batch, (x_train, y_train) in enumerate(train_dataloader):
    x_train, y_train = x_train.to(device), y_train.to(device)
    model_0.train()
    y_predict = model_0(x_train)
    loss_of_train = loss_function(y_predict, y_train)

    train_loss += loss_of_train

    optimize_the_function.zero_grad()
    loss_of_train.backward()
    optimize_the_function.step()
    y_predicts_class = torch.argmax(torch.softmax(y_predict, dim=1), dim=1)

    train_accuracy += (y_predicts_class == y_train).sum().item() / len(y_predict)

  train_loss = train_loss / len(train_dataloader)
  train_accuracy = train_accuracy / len(train_dataloader)

  test_loss , test_accuracy = 0, 0
  model_0.eval()
  with torch.inference_mode():
    for batch, (x_test, y_test) in enumerate(test_dataloader):
      x_test , y_test = x_test.to(device), y_test.to(device)
      test_predicts = model_0(x_test)
      loss_of_test = loss_function(test_predicts, y_test)
      test_loss += loss_of_test

      test_predicts_label = test_predicts.argmax(dim=1)
      test_accuracy += (test_predicts_label == y_test).sum().item() / len(test_predicts_label)

    test_loss = test_loss / len(test_dataloader)
    test_accuracy = test_accuracy / len(test_dataloader)

  if epoch % 50 == 0 :
    print(f"Epoch:{epoch}, Train loss:{train_loss:.2f}, Test loss:{test_loss:.2f}, Train accuracy:{train_accuracy:.2f}%, Test accuracy:{test_accuracy:.2f}%")

  results['train_loss'].append(train_loss)
  results['train_accuracy'].append(train_accuracy)
  results['test_loss'].append(test_loss)
  results['test_accuracy'].append(test_accuracy)

  train_time_end = timer()
  total_time = (train_time_start - train_time_end) / 60
print(f"Total time required for train: {total_time:.2f} minute")

train_loss_plt = results["train_loss"]
train_accuracy_plt = results["train_accuracy"]
test_loss_plt = results["test_loss"]
test_accuracy_plt = results["test_accuracy"]

train_loss_plt[4]

train_loss_plt_numpy = np.asarray([tensor.detach().cpu().numpy() for tensor in train_loss_plt])
test_loss_plt_numpy = np.asarray([tensor.detach().cpu().numpy() for tensor in test_loss_plt])
train_accuracy_plt_numpy = np.asarray(train_accuracy_plt)
test_accuracy_plt_numpy = np.asarray(test_accuracy_plt)

train_loss_plt_numpy[4]

Epochs = range(len(train_loss_plt_numpy))

plt.figure(figsize=(16, 8))
plt.subplot(1, 2, 1)
plt.plot(Epochs, train_loss_plt_numpy, label="train loss")
plt.plot(Epochs, test_loss_plt_numpy, label="test loss")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(Epochs, train_accuracy_plt_numpy, label="train accuracy")
plt.plot(Epochs, test_accuracy_plt_numpy, label="test accuracy")
plt.legend()
plt.show()

